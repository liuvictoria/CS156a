{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# creating data\n",
    "###################\n",
    "\n",
    "def generate_point(boundary1, boundary2):\n",
    "    \"\"\"\n",
    "    Generate random two-dimensional point on \n",
    "    [boundary1, boundary 2] X [boundary1, boundary2] space.\n",
    "    Returns ndarray of (x, y) point\n",
    "    \"\"\"\n",
    "    random_point = np.zeros(2)g\n",
    "    for i in range(2):\n",
    "        random_point[i] = np.random.uniform(boundary1, boundary2, 1)\n",
    "    return random_point\n",
    "\n",
    "def label_point(random_point):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        random_point (x1, x2), array-like\n",
    "    \"\"\"\n",
    "    x1, x2 = random_point\n",
    "    return np.sign(x2 - x1 + .25 * np.sin(np.pi * x1))\n",
    "    \n",
    "\n",
    "def create_data(N = 100):\n",
    "    \"\"\"\n",
    "    Connect X and Y for a certain number of points\n",
    "    \"\"\"\n",
    "    X = np.zeros((N, 2))\n",
    "    Y = np.zeros((N, ))\n",
    "    for i in range(N):\n",
    "        X[i] = generate_point(-1, 1)\n",
    "        Y[i] = label_point(X[i])\n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "##################\n",
    "# SVM Functions\n",
    "##################\n",
    "\n",
    "def hard_margin_svm(X_train, Y_train, C = np.inf, kernel = 'rbf', gamma = 1.5):\n",
    "    support_vector_machine = SVC(C = C, kernel = kernel, gamma = gamma)\n",
    "    support_vector_machine.fit(X_train, Y_train)\n",
    "    return support_vector_machine\n",
    "\n",
    "\n",
    "def svm_error(support_vector_machine, X, Y):\n",
    "    svm_error_freq = 1 - support_vector_machine.score(X, Y)\n",
    "    return svm_error_freq\n",
    "\n",
    "def hard_svm_nonseparable(X_train, Y_train, C = np.inf, kernel = 'rbf', gamma = 1.5):\n",
    "    support_vector_machine = hard_margin_svm(X_train, Y_train, C = C, kernel = kernel, gamma = gamma)\n",
    "    error_in = svm_error(support_vector_machine, X_train, Y_train)\n",
    "    if error_in == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "####################\n",
    "# find Ein or Eout and other helper functions\n",
    "####################\n",
    "\n",
    "def error_freq(g_classification, Y):\n",
    "    error_sum = np.sum(g_classification != Y)\n",
    "    error = error_sum / len(Y)\n",
    "    return error\n",
    "\n",
    "\n",
    "def euclidian_distance(x, mu):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x : single point (x1, x2)\n",
    "        mu : single centroid (x1, x2)\n",
    "    Remember to square the norm for regular RBF / Lloyd\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(x - mu)\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "# lloyd rbf and pinv\n",
    "#####################\n",
    "\n",
    "def find_new_mus(X_train, which_mus):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X_train: ndarray of (x1, x2) as elements\n",
    "        which_mus: ndarray, same indices as X_train,\n",
    "            detailing which mu the data point is part to\n",
    "    Outputs:\n",
    "        new_mus\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train_1, X_train_2 = zip(*X_train)\n",
    "    X_train_1, X_train_2 = np.array(X_train_1), np.array(X_train_2)\n",
    "    K = len(np.unique(which_mus))\n",
    "    new_mus = np.zeros([K, 2])\n",
    "    for i in range(K):\n",
    "        if np.sum(which_mus == i) > 0:\n",
    "            X_mu_slice_1 = X_train_1[which_mus == i]\n",
    "            new_mus[i, 0] = np.sum(X_mu_slice_1) / len(X_mu_slice_1)\n",
    "        \n",
    "            X_mu_slice_2 = X_train_2[which_mus == i]\n",
    "            new_mus[i, 1] = np.sum(X_mu_slice_2) / len(X_mu_slice_2)\n",
    "    new_mus = np.sort(new_mus)\n",
    "    return new_mus\n",
    "\n",
    "\n",
    "def recluster_by_distance(X_train, mus):\n",
    "    \"\"\"\n",
    "    Culmination of euclidian_distance(x, mu) and \n",
    "    get_best_mus(x, mus)\n",
    "    second part of iterative Lloyd's algorithm, whereby we\n",
    "    recluster the points based on which mu they are closest to\n",
    "    \"\"\"\n",
    "    which_mu = np.zeros([len(X_train), ])\n",
    "    for i, _ in enumerate(X_train):\n",
    "        which_mu[i] = get_best_mu(X_train[i], mus)\n",
    "    \n",
    "    return which_mu\n",
    "\n",
    "\n",
    "\n",
    "def get_best_mu(x, mus):\n",
    "    \"\"\"\n",
    "    Given K mus, which mu is closest to x?\n",
    "    Inputs:\n",
    "        x : single point (x1, x2)\n",
    "        mus : vector of mus, of length K\n",
    "    \"\"\"\n",
    "    #important to sort so we can link mus with mu_sorted\n",
    "    mus = np.sort(mus)\n",
    "    K = len(mus)\n",
    "    distances = np.zeros([K, ])\n",
    "    for i, mu in enumerate(mus):\n",
    "        distances[i] = euclidian_distance(x, mu)\n",
    "    best_mu = np.argmin(distances)\n",
    "    return best_mu\n",
    "\n",
    "\n",
    "\n",
    "def no_empty_clusters(which_mu, K):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        which_mu: ndarray of which mu the training data is attached to\n",
    "    \"\"\"\n",
    "    mus = np.arange(K)\n",
    "    if np.sum(np.isin(mus, which_mu)) < K:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def lloyd_clusters(X_train, K):\n",
    "    \"\"\"\n",
    "    iterative process of Lloyd's algorithm\n",
    "    Returns False if a cluster is empty\n",
    "    \"\"\"\n",
    "    #initialize centroids randomly\n",
    "    mus = np.array([generate_point(-1, 1) for _ in range(K)])\n",
    "    \n",
    "    #initialize which_mu for comparison later\n",
    "    which_mu = np.zeros([K, ])\n",
    "    letsrun = True\n",
    "    iterat = 0\n",
    "    \n",
    "    #run until convergence\n",
    "    while letsrun:\n",
    "        #recluster based on current mus\n",
    "        new_which_mu = recluster_by_distance(X_train, mus)\n",
    "        \n",
    "        #note this will always be false on the first run\n",
    "        #if true, that means we've converged\n",
    "        if np.array_equal(which_mu, new_which_mu) or iterat == 200:\n",
    "            letsrun = False\n",
    "        \n",
    "        #else run Lloyd's algorithm; find new mus\n",
    "        else:\n",
    "            mus = find_new_mus(X_train, new_which_mu)\n",
    "            which_mu = new_which_mu\n",
    "            iterat += 1\n",
    "    \n",
    "    #check for empty clusters\n",
    "    if no_empty_clusters(which_mu, K):\n",
    "        return mus, which_mu\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def make_phi_matrix(X, K, mus, gamma):\n",
    "    '''\n",
    "    calculate phi matrix, according to slide 14/lecture 20\n",
    "    '''\n",
    "    #add one column for bias term\n",
    "    phi = np.ones([len(X), K + 1])\n",
    "    for i in range(1, K + 1):\n",
    "        for j in range(len(X)):\n",
    "            phi[j, i] = np.exp(-gamma * (euclidian_distance(X[j], mus[i-1]))**2)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def lloyd_algorithm_error(\n",
    "    X_train, Y_train,\n",
    "    X_test, Y_test,\n",
    "    K = 9, gamma = 1.5, error_type = 'Ein'\n",
    "    ):\n",
    "    '''\n",
    "    error for lloyd algorithm, gives back -1 if empty cluster\n",
    "    '''\n",
    "    try:\n",
    "        mus, which_mu = lloyd_clusters(X_train, K)\n",
    "        \n",
    "    except (RuntimeWarning, TypeError):\n",
    "#         print('empty cluster error caught')\n",
    "        return -1\n",
    "    \n",
    "    mus = np.sort(mus)\n",
    "    #calculate phi matrix, according to slide 14/lecture 20\n",
    "    #add one column for bias term\n",
    "    phi_train = make_phi_matrix(X_train, K, mus, gamma = gamma)\n",
    "    #use pseudo-inverse to find weights and bias; only trained on training set\n",
    "    weights = np.dot(np.linalg.pinv(phi_train), Y_train)\n",
    "\n",
    "    if error_type == 'Ein':\n",
    "        #get hypothesis labels\n",
    "        Y_train_h = np.sign(np.dot(phi_train, weights))\n",
    "        #get error\n",
    "        error_in = error_freq(Y_train_h, Y_train)\n",
    "        return error_in\n",
    "\n",
    "    elif error_type == 'Eout':\n",
    "        #still need to make the phi matrix\n",
    "        phi_test = make_phi_matrix(X_test, K, mus, gamma = gamma)\n",
    "        #get hypothesis labels\n",
    "        Y_test_h = np.sign(np.dot(phi_test, weights))\n",
    "        #get error\n",
    "        error_out = error_freq(Y_test_h, Y_test)\n",
    "        return error_out\n",
    "    else:\n",
    "        print ('type in Ein or Eout')\n",
    "\n",
    "        \n",
    "        \n",
    "def lloyd_error_single_run(K = 9, gamma = 1.5, error_type = 'Eout'):\n",
    "    '''\n",
    "    deals with empty clusters. Polished version of lloyd_algorithm_error\n",
    "    '''\n",
    "    lloyd_error = -1\n",
    "    while lloyd_error == -1:\n",
    "        X_train, Y_train = create_data()\n",
    "        X_test, Y_test = create_data()\n",
    "\n",
    "        lloyd_error = lloyd_algorithm_error(\n",
    "            X_train, Y_train,\n",
    "            X_test, Y_test,\n",
    "            K = K, gamma = gamma, error_type = error_type\n",
    "            )\n",
    "\n",
    "    return lloyd_error\n",
    "\n",
    "        \n",
    "def compare_svm_vs_unsupervised(K = 9, gamma = 1.5, error_type = 'Eout', C = np.inf, kernel = 'rbf'):\n",
    "    \n",
    "    lloyd_error = -1\n",
    "    while lloyd_error == -1:\n",
    "        X_train, Y_train = create_data()\n",
    "        X_test, Y_test = create_data()\n",
    "\n",
    "        lloyd_error = lloyd_algorithm_error(\n",
    "            X_train, Y_train,\n",
    "            X_test, Y_test,\n",
    "            K = K, gamma = gamma, error_type = error_type\n",
    "            )\n",
    "        iterat += 1\n",
    "\n",
    "    support_vector_machine = hard_margin_svm(X_train, Y_train, C = C, kernel = kernel, gamma = gamma)\n",
    "    if error_type == 'Eout':\n",
    "        X, Y = X_test, Y_test\n",
    "    else:\n",
    "        X, Y = X_train, Y_train\n",
    "    svm_error_ = svm_error(support_vector_machine, X, Y)\n",
    "\n",
    "    return svm_error_ < lloyd_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data    \n",
    "X_train, Y_train = create_data()\n",
    "X_test, Y_test = create_data()\n",
    "\n",
    "# question 13\n",
    "def question_13(runs = runs):\n",
    "    separable_tally = 0\n",
    "    for i in range(runs):\n",
    "        X_train, Y_train = create_data()\n",
    "        #add True or False (i.e. 1 or 0)\n",
    "        separable_tally += hard_svm_nonseparable(X_train, Y_train)\n",
    "    print(f'percentage of separable datasets: {separable_tally / runs}')\n",
    "    return True\n",
    "# question_13()\n",
    "# 1.0\n",
    "\n",
    "\n",
    "# question 14\n",
    "def question_14(runs = runs, K = 9, gamma = 1.5, error_type = 'Eout'):\n",
    "    #same parameters are default, so no need to actually repass them in\n",
    "    svm_is_better = 0\n",
    "    for run in range(runs):\n",
    "        print(f'run {run}')\n",
    "        svm_is_better += compare_svm_vs_unsupervised(\n",
    "            K = K, gamma = gamma, error_type = error_type\n",
    "            )\n",
    "    return svm_is_better / runs\n",
    "# question_14()\n",
    "# 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "run: 1\n",
      "run: 2\n",
      "run: 3\n",
      "run: 4\n",
      "run: 5\n",
      "run: 6\n",
      "run: 7\n",
      "run: 8\n",
      "run: 9\n",
      "run: 10\n",
      "run: 11\n",
      "run: 12\n",
      "run: 13\n",
      "run: 14\n",
      "run: 15\n",
      "run: 16\n",
      "run: 17\n",
      "run: 18\n",
      "run: 19\n",
      "run: 20\n",
      "run: 21\n",
      "run: 22\n",
      "run: 23\n",
      "run: 24\n",
      "run: 25\n",
      "run: 26\n",
      "run: 27\n",
      "run: 28\n",
      "run: 29\n",
      "run: 30\n",
      "run: 31\n",
      "run: 32\n",
      "run: 33\n",
      "run: 34\n",
      "run: 35\n",
      "run: 36\n",
      "run: 37\n",
      "run: 38\n",
      "run: 39\n",
      "In sample error for 1.5 : 0.03850000000000002\n",
      "Out sample error for 1.5: 0.04800000000000002\n",
      "In sample error for 2  : 0.025500000000000012\n",
      "Out sample error for 2  : 0.044250000000000025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 17\n",
    "def question_17(runs = runs):\n",
    "    error_in_15, error_out_15, error_in_2, error_out_2 = 0, 0, 0, 0\n",
    "    for run in range(runs):\n",
    "        print (f'run: {run}')\n",
    "        \n",
    "        X_train, Y_train = create_data()\n",
    "        X_test, Y_test = create_data()\n",
    "        \n",
    "        error_in_15 += lloyd_error_single_run(\n",
    "        K = 9, gamma = 1.5, error_type = 'Ein'\n",
    "            )\n",
    "\n",
    "        error_out_15 += lloyd_error_single_run(\n",
    "        K = 9, gamma = 1.5, error_type = 'Eout'\n",
    "            )\n",
    "\n",
    "        error_in_2 += lloyd_error_single_run(\n",
    "        K = 12, gamma = 2, error_type = 'Ein'\n",
    "            )\n",
    "\n",
    "        error_out_2 += lloyd_error_single_run(\n",
    "        K = 12, gamma = 2, error_type = 'Eout'\n",
    "            )\n",
    "    print(f'In sample error for 1.5 : {error_in_15 / runs}')\n",
    "    print(f'Out sample error for 1.5: {error_out_15 / runs}')\n",
    "    print(f'In sample error for 2  : {error_in_2 / runs}')\n",
    "    print(f'Out sample error for 2  : {error_out_2 / runs}')\n",
    "    return True\n",
    "question_17(runs = 40)\n",
    "# In sample error for 1.5 : 0.03469999999999993\n",
    "# Out sample error for 1.5: 0.05404999999999995\n",
    "# In sample error for 2  : 0.024149999999999925\n",
    "# Out sample error for 2  : 0.04529999999999995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 18\n",
    "def question_18(runs = runs):\n",
    "    zero_error_count = 0\n",
    "    for run in range(runs):\n",
    "        print (f'run: {run}')\n",
    "        \n",
    "        X_train, Y_train = create_data()\n",
    "        X_test, Y_test = create_data()\n",
    "        \n",
    "        error_in = lloyd_error_single_run(\n",
    "        K = 9, gamma = 1.5, error_type = 'Ein'\n",
    "            )\n",
    "        if error_in == 0:\n",
    "            zero_error_count += 1\n",
    "\n",
    "    print(f'0 E_in percentage: {zero_error_count / runs}')\n",
    "\n",
    "    return True\n",
    "# question_18()\n",
    "# 0.0 for 30 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "run: 1\n",
      "run: 2\n",
      "run: 3\n",
      "run: 4\n",
      "run: 5\n",
      "run: 6\n",
      "run: 7\n",
      "run: 8\n",
      "run: 9\n",
      "run: 10\n",
      "run: 11\n",
      "run: 12\n",
      "run: 13\n",
      "run: 14\n",
      "run: 15\n",
      "run: 16\n",
      "run: 17\n",
      "run: 18\n",
      "run: 19\n",
      "run: 20\n",
      "run: 21\n",
      "run: 22\n",
      "run: 23\n",
      "run: 24\n",
      "run: 25\n",
      "run: 26\n",
      "run: 27\n",
      "run: 28\n",
      "run: 29\n",
      "run: 30\n",
      "run: 31\n",
      "run: 32\n",
      "run: 33\n",
      "run: 34\n",
      "run: 35\n",
      "run: 36\n",
      "run: 37\n",
      "run: 38\n",
      "run: 39\n",
      "run: 40\n",
      "run: 41\n",
      "run: 42\n",
      "run: 43\n",
      "run: 44\n",
      "run: 45\n",
      "run: 46\n",
      "run: 47\n",
      "run: 48\n",
      "run: 49\n",
      "run: 50\n",
      "run: 51\n",
      "run: 52\n",
      "run: 53\n",
      "run: 54\n",
      "run: 55\n",
      "run: 56\n",
      "run: 57\n",
      "run: 58\n",
      "run: 59\n",
      "run: 60\n",
      "run: 61\n",
      "run: 62\n",
      "run: 63\n",
      "run: 64\n",
      "run: 65\n",
      "run: 66\n",
      "run: 67\n",
      "run: 68\n",
      "run: 69\n",
      "run: 70\n",
      "run: 71\n",
      "run: 72\n",
      "run: 73\n",
      "run: 74\n",
      "run: 75\n",
      "run: 76\n",
      "run: 77\n",
      "run: 78\n",
      "run: 79\n",
      "run: 80\n",
      "run: 81\n",
      "run: 82\n",
      "run: 83\n",
      "run: 84\n",
      "run: 85\n",
      "run: 86\n",
      "run: 87\n",
      "run: 88\n",
      "run: 89\n",
      "run: 90\n",
      "run: 91\n",
      "run: 92\n",
      "run: 93\n",
      "run: 94\n",
      "run: 95\n",
      "run: 96\n",
      "run: 97\n",
      "run: 98\n",
      "run: 99\n",
      "run: 100\n",
      "run: 101\n",
      "run: 102\n",
      "run: 103\n",
      "run: 104\n",
      "run: 105\n",
      "run: 106\n",
      "run: 107\n",
      "run: 108\n",
      "run: 109\n",
      "run: 110\n",
      "run: 111\n",
      "run: 112\n",
      "run: 113\n",
      "run: 114\n",
      "run: 115\n",
      "run: 116\n",
      "run: 117\n",
      "run: 118\n",
      "run: 119\n",
      "run: 120\n",
      "run: 121\n",
      "run: 122\n",
      "run: 123\n",
      "run: 124\n",
      "run: 125\n",
      "run: 126\n",
      "run: 127\n",
      "run: 128\n",
      "run: 129\n",
      "run: 130\n",
      "run: 131\n",
      "run: 132\n",
      "run: 133\n",
      "run: 134\n",
      "run: 135\n",
      "run: 136\n",
      "run: 137\n",
      "run: 138\n",
      "run: 139\n",
      "run: 140\n",
      "run: 141\n",
      "run: 142\n",
      "run: 143\n",
      "run: 144\n",
      "run: 145\n",
      "run: 146\n",
      "run: 147\n",
      "run: 148\n",
      "run: 149\n",
      "run: 150\n",
      "run: 151\n",
      "run: 152\n",
      "run: 153\n",
      "run: 154\n",
      "run: 155\n",
      "run: 156\n",
      "run: 157\n",
      "run: 158\n",
      "run: 159\n",
      "run: 160\n",
      "run: 161\n",
      "run: 162\n",
      "run: 163\n",
      "run: 164\n",
      "run: 165\n",
      "run: 166\n",
      "run: 167\n",
      "run: 168\n",
      "run: 169\n",
      "run: 170\n",
      "run: 171\n",
      "run: 172\n",
      "run: 173\n",
      "run: 174\n",
      "run: 175\n",
      "run: 176\n",
      "run: 177\n",
      "run: 178\n",
      "run: 179\n",
      "run: 180\n",
      "run: 181\n",
      "run: 182\n",
      "run: 183\n",
      "run: 184\n",
      "run: 185\n",
      "run: 186\n",
      "run: 187\n",
      "run: 188\n",
      "run: 189\n",
      "run: 190\n",
      "run: 191\n",
      "run: 192\n",
      "run: 193\n",
      "run: 194\n",
      "run: 195\n",
      "run: 196\n",
      "run: 197\n",
      "run: 198\n",
      "run: 199\n",
      "In sample error for 9  : 0.033049999999999954\n",
      "Out sample error for 9 : 0.05639999999999995\n",
      "In sample error for 12 : 0.023849999999999958\n",
      "Out sample error for 12: 0.04339999999999992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 16\n",
    "def question_16(runs = runs):\n",
    "    error_in_9, error_out_9, error_in_12, error_out_12 = 0, 0, 0, 0\n",
    "    for run in range(runs):\n",
    "        print (f'run: {run}')\n",
    "        \n",
    "        X_train, Y_train = create_data()\n",
    "        X_test, Y_test = create_data()\n",
    "        \n",
    "        error_in_9 += lloyd_error_single_run(\n",
    "        K = 9, gamma = 1.5, error_type = 'Ein'\n",
    "            )\n",
    "\n",
    "        error_out_9 += lloyd_error_single_run(\n",
    "        K = 9, gamma = 1.5, error_type = 'Eout'\n",
    "            )\n",
    "\n",
    "        error_in_12 += lloyd_error_single_run(\n",
    "        K = 12, gamma = 1.5, error_type = 'Ein'\n",
    "            )\n",
    "\n",
    "        error_out_12 += lloyd_error_single_run(\n",
    "        K = 12, gamma = 1.5, error_type = 'Eout'\n",
    "            )\n",
    "    print(f'In sample error for 9  : {error_in_9 / runs}')\n",
    "    print(f'Out sample error for 9 : {error_out_9 / runs}')\n",
    "    print(f'In sample error for 12 : {error_in_12 / runs}')\n",
    "    print(f'Out sample error for 12: {error_out_12 / runs}')\n",
    "    return True\n",
    "# question_16(runs = runs)\n",
    "# In sample error for 9  : 0.033049999999999954\n",
    "# Out sample error for 9 : 0.05639999999999995\n",
    "# In sample error for 12 : 0.023849999999999958\n",
    "# Out sample error for 12: 0.04339999999999992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "run 1\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "run 2\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n",
      "empty cluster error caught\n",
      "disregarding empty cluster, working on new set of points and random clusters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 15\n",
    "def question_15(runs = runs, K = 12, gamma = 1.5, error_type = 'Eout'):\n",
    "    svm_is_better = 0\n",
    "    for run in range(runs):\n",
    "        print(f'run {run}')\n",
    "        svm_is_better += compare_svm_vs_unsupervised(\n",
    "            K = K, gamma = gamma, error_type = error_type\n",
    "            )\n",
    "    return svm_is_better / runs\n",
    "\n",
    "#run later\n",
    "question_15()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
