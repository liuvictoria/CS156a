{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question number, 2-10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between svms for 0 vs all and 1 vs all: 1793\n",
      "[2179, 386]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import sklearn.svm\n",
    "\n",
    "def fetch_data(filename):\n",
    "    raw_data = pd.read_csv(filename, sep=\"  \", header=None, engine = 'python')\n",
    "    raw_data.columns = [\"Number\", \"Intensity\", \"Symmetry\"]\n",
    "    return raw_data\n",
    "\n",
    "def label_data(raw_data_deep, num1, num2 = None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        raw_data_deep: (pandas df), Columns: Number, Intensity, Symmetry\n",
    "        num1: (int), num1 vs all or num1 vs num2 classifier\n",
    "        num2: (None or int), None if num1 vs all classifier\n",
    "    \n",
    "    Outputs:\n",
    "        X: (ndarray), X.shape = (relevant data points, 2), intensity, symmetry\n",
    "        Y: (ndarray), Y.shape = (relevant data points, ), classification\n",
    "    \n",
    "    \"\"\"\n",
    "    #make a deep copy of raw_data_deep so that raw_data_deep isn't modified\n",
    "    raw_data = raw_data_deep.copy(deep = True)\n",
    "    \n",
    "    #If doing num1 vs num2 classifier, remove all other numbers\n",
    "    if num2 != None:\n",
    "        remove_indices = raw_data[(\n",
    "            (raw_data.Number != num1) & (raw_data.Number != num2)\n",
    "            )].index #.index provides Int64Index to remove. Don't use when actually indexing df\n",
    "        raw_data = raw_data.drop(remove_indices)\n",
    "    \n",
    "    #label non-num1 points -1; this is either all other numbers or num2\n",
    "    negative_indices = raw_data['Number'] != num1 #gives boolean array\n",
    "    raw_data.loc[negative_indices, 'Number'] = -1\n",
    "    \n",
    "    #label num1 with 1; this step must come after the previous step, logically\n",
    "    raw_data['Number'] = raw_data['Number'].replace(num1, 1)\n",
    "    \n",
    "    #convert column 0 to Y classification; convert columns 1 & 2 to X inputs\n",
    "    X = raw_data.loc[:, ['Intensity', 'Symmetry']].to_numpy()\n",
    "    Y = raw_data.loc[:, 'Number'].to_numpy()\n",
    "    \n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def svm_error(support_vector_machine, X_testing, Y_testing):\n",
    "    svm_error_freq = 1 - support_vector_machine.score(X_testing, Y_testing)\n",
    "    return svm_error_freq\n",
    "\n",
    "\n",
    "def svm_single_run_error(\n",
    "    X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 1, degree = 2\n",
    "    ):\n",
    "    \"\"\"\n",
    "    The \"brains\" of the experimental parts for questions 2-6, 9-10;\n",
    "    fits support_vector_machine using X_in and Y_in and returns the error.\n",
    "    \n",
    "    Inputs:\n",
    "        X_in (ndarray), in-sample X generated from label_data; X_in.shape = (relevant points, 2)\n",
    "        Y_in (ndarray), in-sample Y generated from label_data; Y_in.shape = (relevant points, )\n",
    "        error_type = \"Ein\" (string), either \"Ein\" or \"Eout\"; otherwise will throw Error\n",
    "        X_out = None (None or ndarray), if error_type = \"Eout\", X_out must be defined\n",
    "        Y_out = None (None or ndarray), if error_type = \"Eout\", Y_out must be defined\n",
    "        kernel = 'poly' (string), other options \"linear\", \"rbf\"\n",
    "        C = 1 (float), can define and usually determined using validation; soft margin error\n",
    "        degree = 2 (int), the order of the polynomial when using \"poly\"; otherwise disregarded\n",
    "    \n",
    "    Outputs:\n",
    "        svm_error_freq (float), (in-sample or out out-sample) error of the support vector machine\n",
    "    \n",
    "    \"\"\"\n",
    "    #train/ fit svm\n",
    "    support_vector_machine = sklearn.svm.SVC(kernel = kernel, C = C, degree = degree, coef0 = 1, gamma = 1)\n",
    "    support_vector_machine.fit(X_in, Y_in)\n",
    "        \n",
    "    #svm error\n",
    "    if error_type == \"Ein\":\n",
    "        svm_error_freq = svm_error(support_vector_machine, X_in, Y_in)\n",
    "    elif error_type == \"Eout\":\n",
    "        if X_out != None and Y_out != None:\n",
    "            svm_error_freq = svm_error(support_vector_machine, X_out, Y_out)\n",
    "        else:\n",
    "            raise Exception(\"Calculating Eout, but did not provide X_out and Y_out\")\n",
    "    else:\n",
    "        raise Exception(\"Invalid error_type, please start again \\n\")\n",
    "    return (svm_error_freq)\n",
    "\n",
    "def svm_count(X_in, Y_in, kernel = 'poly', C = 0.01, degree = 2):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X_in (ndarray), in-sample X generated from label_data; X_in.shape = (relevant points, 2)\n",
    "        Y_in (ndarray), in-sample Y generated from label_data; Y_in.shape = (relevant points, )\n",
    "        kernel = 'poly' (string), other options \"linear\", \"rbf\"\n",
    "        C = 1 (float), can define and usually determined using validation; soft margin error\n",
    "        degree = 2 (int), the order of the polynomial when using \"poly\"; otherwise disregarded\n",
    "        \n",
    "    Outputs:\n",
    "        svm_count\n",
    "    \"\"\"\n",
    "    \n",
    "    #train/ fit svm\n",
    "    support_vector_machine = sklearn.svm.SVC(kernel = kernel, C = C, degree = degree, coef0 = 1, gamma = 1)\n",
    "    support_vector_machine.fit(X_in, Y_in)\n",
    "        \n",
    "    #get number of support vectors\n",
    "    svm_count = len(support_vector_machine.support_)\n",
    "\n",
    "    return svm_count\n",
    "\n",
    "\n",
    "def svm_cross_validation_error(X_partition_tuple, Y_partition_tuple, kernel = 'poly', C = 1, degree = 2):\n",
    "    n_fold = len(Y_partition_tuple)\n",
    "    cv_error_total = 0\n",
    "    for i in range(n_fold):\n",
    "        #separate training and validation data\n",
    "        #splice out training data; use list for later modification\n",
    "        X_training = list(X_partition_tuple)\n",
    "        Y_training = list(Y_partition_tuple)\n",
    "        \n",
    "        #pop out validation data\n",
    "        X_training.pop(i)\n",
    "        Y_training.pop(i)\n",
    "        \n",
    "        #squeezing the list from 2d to 1d and make into ndarray\n",
    "        X_training = np.asarray(list(\n",
    "            itertools.chain(*X_training)\n",
    "            ))\n",
    "        Y_training = np.asarray(list(\n",
    "            itertools.chain(*Y_training)\n",
    "            ))\n",
    "        \n",
    "        #get validation data\n",
    "        X_validation = X_partition_tuple[i] #ndarray\n",
    "        Y_validation = Y_partition_tuple[i] #ndarray\n",
    "        \n",
    "        #train/ fit svm\n",
    "        support_vector_machine = sklearn.svm.SVC(kernel = kernel, C = C, degree = degree, coef0 = 1, gamma = 1)\n",
    "        support_vector_machine.fit(X_training, Y_training)\n",
    "        \n",
    "        #svm error_freq\n",
    "        svm_error_freq = svm_error(support_vector_machine, X_validation, Y_validation)\n",
    "        \n",
    "        #add to total error tally\n",
    "        cv_error_total += svm_error_freq\n",
    "    cv_error_freq = cv_error_total / n_fold\n",
    "    return cv_error_freq\n",
    "\n",
    "def partition_for_cross_validation(X, Y, n_fold):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        X (ndarray)\n",
    "        Y (ndarray)\n",
    "        n_fold (int) # of partitions, usually 10\n",
    "    \n",
    "    Outputs:\n",
    "        X_partition_list = (nested tuple of ndarrays), len(X_partition) = n_fold\n",
    "        Y_partition_list = (nested tuple of ndarrays), len(Y_partition) = n_fold\n",
    "        \n",
    "    Notes:\n",
    "        X_partition and Y_partition indices hold the input / classification of the same point;\n",
    "        this is done by generating a separate array of random indices, index_permutation,\n",
    "        and choosing every n_foldth index as the index to use on both X and Y.\n",
    "        This is done here because none of the other problems require random petmutation,\n",
    "        so there is no need to find random indices for the earlier functions, like label_data().\n",
    "    \"\"\"\n",
    "    data_length = len(X)\n",
    "    index_permutation = np.random.permutation(data_length)\n",
    "    \n",
    "    X_partition_list = []\n",
    "    Y_partition_list = []\n",
    "\n",
    "    for fold_count in range(n_fold):\n",
    "        #index at every nth fold, starting at different indices for different blocks\n",
    "        block_indices = index_permutation[fold_count::n_fold]\n",
    "        #fancy indexing for ndarrays! :D\n",
    "        X_block = X[block_indices]\n",
    "        Y_block = Y[block_indices]\n",
    "        X_partition_list.append(X_block)\n",
    "        Y_partition_list.append(Y_block)\n",
    "        \n",
    "    X_partition_tuple = tuple(X_partition_list)\n",
    "    Y_partition_tuple = tuple(Y_partition_list)\n",
    "    \n",
    "    return(X_partition_tuple, Y_partition_tuple)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_partition_tuple, Y_partition_tuple = partition_for_cross_validation(X, Y, 10)\n",
    "#svm_cross_validation_error(X_partition_tuple, Y_partition_tuple, kernel = 'poly', C = .001, degree = 2)\n",
    "#svm_count(X_in, Y_in, kernel = 'poly', C = 1, degree = 2)\n",
    "\n",
    "\n",
    "\n",
    "print('Enter question number, 2-10')\n",
    "question = int(input())\n",
    "\n",
    "\n",
    "raw_data_train = fetch_data(\"number_train.txt\")\n",
    "raw_data_test = fetch_data(\"number_test.txt\")\n",
    "\n",
    "if question == 2:\n",
    "    error_list = []\n",
    "    for i in range(0, 9, 2):\n",
    "        X_in, Y_in = label_data(raw_data_train, i)\n",
    "        e_in = svm_single_run_error(X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 0.01, degree = 2)\n",
    "        error_list.append([i, e_in])\n",
    "        print (\"{i} versus all: {e_in} \\n\".format(i = i, e_in = e_in))\n",
    "    i, worst_error = max(error_list, key=lambda x: x[1])\n",
    "    print ('Worst classifier is {i} versus all at {worst_error}'.format(\n",
    "        i = i, worst_error = worst_error))\n",
    "    \n",
    "if question == 3:\n",
    "    error_list = []\n",
    "    for i in range(1, 10, 2):\n",
    "        X_in, Y_in = label_data(raw_data_train, i)\n",
    "        e_in = svm_single_run_error(X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 0.01, degree = 2)\n",
    "        error_list.append([i, e_in])\n",
    "        print (\"{i} versus all: {e_in} \\n\".format(i = i, e_in = e_in))\n",
    "    i, best_error = min(error_list, key=lambda x: x[1])\n",
    "    print ('Best classifier is {i} versus all at {worst_error}'.format(\n",
    "        i = i, worst_error = worst_error))\n",
    "\n",
    "if question == 4:\n",
    "    numbers = [0, 1]\n",
    "    svm_count_list = []\n",
    "    for i in numbers:\n",
    "        X_in, Y_in = label_data(raw_data_train, i)\n",
    "        svm_tally = svm_count(X_in, Y_in, kernel = 'poly', C = 0.01, degree = 2)\n",
    "        svm_count_list.append(svm_tally)\n",
    "    svm_difference = svm_count_list[0] - svm_count_list[1]\n",
    "    print ('Difference between svms for 0 vs all and 1 vs all: {svm_difference}'.format(\n",
    "        svm_difference = svm_difference\n",
    "        ))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09024825126868741"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = fetch_data(\"number_train.txt\")\n",
    "X_in, Y_in = label_data(raw_data, 3)\n",
    "svm_single_run_error(X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 0.01, degree = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[9, 2], [3, 4]]\n",
    "max(a, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08846523110684401"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = fetch_data(\"number_train.txt\")\n",
    "X_in, Y_in = label_data(raw_data, 7)\n",
    "svm_single_run_error(X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 0.01, degree = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08832807570977919"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = fetch_data(\"number_train.txt\")\n",
    "X_in, Y_in = label_data(raw_data, 9)\n",
    "svm_single_run_error(X_in, Y_in, error_type = \"Ein\", X_out = None, Y_out = None, kernel = 'poly', C = 0.01, degree = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list2d = [[1,2,3], [4,5,6], [7], [8,9]]\n",
    "merged = np.asarray(list(itertools.chain(*list2d)))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[103]\n",
      "\n",
      "[103]\n",
      "[103, 103]\n",
      "\n",
      "[103, 103]\n",
      "[103, 103, 103]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def append_103(x=[]):\n",
    "    print (x)\n",
    "    x.append(103)\n",
    "    print(x)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "append_103()\n",
    "append_103()\n",
    "append_103()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fa59644e4064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mappend_103\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mappend_103\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "def append_103(a):\n",
    "    print (a)\n",
    "    a.append(103)\n",
    "    return a\n",
    "x = []\n",
    "append_103(x)\n",
    "append_103(x)\n",
    "append_103(x)\n",
    "\n",
    "print(append_103(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
