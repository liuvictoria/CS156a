{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For N = 10 \n",
      "\n",
      "Average number of iterations:  9.6963 \n",
      "\n",
      "Average error between g and f:  0.10888505999999959 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#problems 9-10\\naverage_iteration, average_error = experiment(100, 10000, 100)\\nprint(\"For N = 100 \\n\")\\nprint(\"Average number of iterations: \", average_iteration, \"\\n\")\\nprint(\"Average error between g and f: \", average_error, \"\\n\\n\\n\")'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "def generate_point(boundary1, boundary2, dimension):\n",
    "    \"\"\"\n",
    "    Generate random two-dimensional point on \n",
    "    [boundary1, boundary 2] X [boundary1, boundary2] space.\n",
    "    Returns ndarray of (x, y) point\n",
    "    \"\"\"\n",
    "    random_point = np.zeros(dimension)\n",
    "    for i in range(dimension):\n",
    "        random_point[i] = np.random.uniform(boundary1, boundary2, 1)\n",
    "    return random_point\n",
    "\n",
    "def generate_target_f():\n",
    "    \"\"\"\n",
    "    Returns slope and intercept of line connecting two random points\n",
    "    \"\"\"\n",
    "    point_1 = generate_point(-1, 1, 2)\n",
    "    point_2 = generate_point(-1, 1, 2)\n",
    "    \n",
    "    # slope = (y2 - y1) / (x2 - x1)\n",
    "    slope = (point_2[1] - point_1[1]) / (point_2[0] - point_1[0])\n",
    "    # intercept = y1 - slope * x1\n",
    "    intercept = point_2[1] - slope * point_2[0]\n",
    "    return(slope, intercept)\n",
    "\n",
    "\n",
    "def classify_point(random_point, slope, intercept):\n",
    "    \"\"\"\n",
    "    Given random_point in (x, y) form and a slope and intercept,\n",
    "    label the point\n",
    "    +1 if it falls above the line\n",
    "    -1 if it falls below the line\n",
    "    \"\"\"\n",
    "    if random_point[1] > slope * random_point[0] + intercept:\n",
    "        classification = 1\n",
    "    else:\n",
    "        classification = -1\n",
    "    return classification\n",
    "\n",
    "\n",
    "def create_data(N, slope, intercept):\n",
    "    \"\"\"\n",
    "    Creates N points for testing data using target f(X) = slope * X + intercept;\n",
    "    Notes:\n",
    "        Target function f is a line connecting two points in X space [-1, 1] x [-1, 1]\n",
    "        Classification is based on whether points lie above or below f\n",
    "        \n",
    "    Inputs:\n",
    "        N (int)\n",
    "        slope (float), from generate_target_f\n",
    "        intercept (float), from generate_target_f\n",
    "        \n",
    "    Outputs:\n",
    "        X (ndarray), X.shape = (N, 3); x0 = 1\n",
    "        Y (ndarray), Y.shsape = (N, )\n",
    "    \"\"\"\n",
    "    # create matrix X, where x0 is always 1, to accomodate w0\n",
    "    X = np.ones((N, 3))\n",
    "    Y = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        random_point = generate_point(-1, 1, 2)\n",
    "        classification = classify_point(random_point, slope, intercept)\n",
    "        X[i, 1:3] = random_point\n",
    "        Y[i] = classification\n",
    "        \n",
    "    return (X, Y)\n",
    "\n",
    "\n",
    "def perceptron(X_training, Y_training):\n",
    "    \"\"\"\n",
    "    Starts with the weight as a zero-vector.\n",
    "    Changes the weight when it meets any misclassified point.\n",
    "    Returns the new weight once all the points are correctly clasified.\n",
    "    \n",
    "    Inputs:\n",
    "        X_training (ndarray), complete input features of all points\n",
    "        Y_training (ndarray), complete training classification of all points\n",
    "        \n",
    "    Outputs:\n",
    "        weight (ndarray), final hypothesis g(X) = Y for perceptron learning\n",
    "        \n",
    "    \"\"\"\n",
    "    feature_length = X_training.shape[1]\n",
    "    weight = np.zeros(feature_length)\n",
    "\n",
    "    while True:\n",
    "        misclassified_point_count = 0\n",
    "        for i in range(len(X_training)):\n",
    "            if isit_misclassified_point(X_training[i], Y_training[i], weight) == True:\n",
    "                weight = adjust_weight(X_training[i], Y_training[i], weight)\n",
    "                misclassified_point_count += 1\n",
    "        if misclassified_point_count == 0:\n",
    "            break\n",
    "            \n",
    "    return weight\n",
    "\n",
    "def perceptron(X_training, Y_training):\n",
    "    \"\"\"\n",
    "    Starts with the weight as a zero-vector.\n",
    "    In a given iteration, checks every single point for misclassification.\n",
    "    At the end of the iteration, randomly chooses a misclassified point for weight adjustment.\n",
    "    Returns the new weight once all the points are correctly classified.\n",
    "    \n",
    "    Inputs:\n",
    "        X_training (ndarray), complete input features of all points\n",
    "        Y_training (ndarray), complete training classification of all points\n",
    "        \n",
    "    Outputs:\n",
    "        weight (ndarray), final hypothesis g(X) = Y for perceptron learning\n",
    "        iteration_count (int), number of iterations for convergence between g and f\n",
    "        \n",
    "    \"\"\"\n",
    "    feature_length = X_training.shape[1]\n",
    "    weight = np.zeros(feature_length)\n",
    "    iteration_count = 0\n",
    "    \n",
    "    while True:\n",
    "        misclassified_points = []\n",
    "        for i in range(len(X_training)):\n",
    "            if isit_misclassified_point(X_training[i], Y_training[i], weight) == True:\n",
    "                misclassified_points.append(i)\n",
    "        if len(misclassified_points) == 0:\n",
    "            break\n",
    "            \n",
    "        random_i = random.choice(misclassified_points)\n",
    "        weight = adjust_weight(X_training[random_i], Y_training[random_i], weight)\n",
    "        iteration_count += 1\n",
    "        \n",
    "    return (weight, iteration_count)\n",
    "\n",
    "def adjust_weight(x_misclassified, y_misclassified, weight):\n",
    "    \"\"\"\n",
    "    Given a single misclassified point and the current weight vector,\n",
    "    adjust the weight to accomodate our misclassifed point.\n",
    "    \n",
    "    Inputs:\n",
    "        x_misclassified (ndarray)\n",
    "        y_misclassified (+/- 1)\n",
    "        weight (ndarray)\n",
    "        \n",
    "    Outputs:\n",
    "        misclassified (boolean)\n",
    "    \"\"\"\n",
    "    adjusted_weight = weight + np.dot(y_misclassified, x_misclassified)\n",
    "    return adjusted_weight\n",
    "\n",
    "\n",
    "def isit_misclassified_point(x, y, weight):\n",
    "    \"\"\"\n",
    "    Given a single point (i.e. vector x and label y)\n",
    "    and a weight that we are currently training or testing, it will determine whether the\n",
    "    current hypothesis weight correctly or incorrectly classifies the point.\n",
    "    Tests hypothesis g(x) = sign (weight . x) == y for classification\n",
    "    \n",
    "    Inputs:\n",
    "        x (ndarray)\n",
    "        y (+/- 1)\n",
    "        weight (must be ndarray)\n",
    "        \n",
    "    Outputs:\n",
    "        misclassified (boolean)\n",
    "    \n",
    "    \"\"\"\n",
    "    if np.sign(np.dot(weight.T, x)) != y:\n",
    "        miclassified = True\n",
    "    else:\n",
    "        miclassified = False\n",
    "    return miclassified\n",
    "\n",
    "def perceptron_error_single_run(X_testing, Y_testing, weight):\n",
    "    \"\"\"\n",
    "    g = (weight . x)\n",
    "    Inputs:\n",
    "        X_testing (ndarray), complete input features of testing set\n",
    "        Y_testing (ndarray), complete accurate classification of testing set, from f(x)\n",
    "        weight (ndarray), generated by perceptron() func as the first element of the tuple\n",
    "    Outputs:\n",
    "        pla_error_freq (float), P[f(x)!= g_pla(x)]\n",
    "    \"\"\"\n",
    "    \n",
    "    N = X_testing.shape[0]\n",
    "    error_count = 0\n",
    "    for i in range(N):\n",
    "        if isit_misclassified_point(X_testing[i], Y_testing[i], weight):\n",
    "            error_count += 1\n",
    "            \n",
    "    pla_error_freq = error_count / N\n",
    "    return pla_error_freq\n",
    "\n",
    "def experiment(N_training, N_testing, runs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        N_training: (int), number of points for training\n",
    "        N_testing: (int), number of points for testing\n",
    "        runs: (int), number of runs\n",
    "    \"\"\"\n",
    "   \n",
    "    average_iteration = 0\n",
    "    average_error = 0\n",
    "    for i in range(runs):\n",
    "            \n",
    "        #generate random function f(X) for every run\n",
    "        slope, intercept = generate_target_f()\n",
    "        \n",
    "        #create training data based on f(X)\n",
    "        X_training, Y_training = create_data(N_training, slope, intercept)\n",
    "        \n",
    "        #get weights for best hypothesis g\n",
    "        weight, iteration_count = perceptron(X_training, Y_training)\n",
    "        average_iteration += iteration_count\n",
    "        \n",
    "        #create testing data based on f(X)\n",
    "        X_testing, Y_testing = create_data(N_testing, slope, intercept)\n",
    "        \n",
    "        #use perceptron_error_single_run to get pla_error_freq\n",
    "        pla_error_freq = perceptron_error_single_run(X_testing, Y_testing, weight)\n",
    "        average_error += pla_error_freq\n",
    "            \n",
    "    #outside forloop\n",
    "    average_iteration /= runs\n",
    "    average_error /= runs\n",
    "    \n",
    "    return (average_iteration, average_error)\n",
    "\n",
    "#problems 7-8\n",
    "average_iteration, average_error = experiment(10, 10000, 1000)\n",
    "print(\"For N = 10 \\n\")\n",
    "print(\"Average number of iterations: \", average_iteration, \"\\n\")\n",
    "print(\"Average error between g and f: \", average_error, \"\\n\\n\\n\")\n",
    "\n",
    "#problems 9-10\n",
    "average_iteration, average_error = experiment(100, 10000, 100)\n",
    "print(\"For N = 100 \\n\")\n",
    "print(\"Average number of iterations: \", average_iteration, \"\\n\")\n",
    "print(\"Average error between g and f: \", average_error, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
